
专家系统
----------------------------------------------------------------------


* 调试环境安装：build 并 tag 本地镜像

```bash
# 后端分支代码路径 
cd /home/apulis//DLWorkspace/src/ClusterBootstrap/
git checkout no_network
git pull
# 重新生成平台配置
./deploy.py --verbose webui

# 更新平台组件
./deploy.py --verbose docker build restfulapi2
docker image  tag  dlworkspace_restfulapi2:latest apulistech/dlworkspace_restfulapi2:latest

./deploy.py --nocache docker build custom-user-dashboard-frontend
docker image  tag  dlworkspace_custom-user-dashboard-frontend:latest   apulistech/dlworkspace_custom-user-dashboard-frontend:latest

./deploy.py --nocache docker build custom-user-dashboard-backend
docker image  tag  dlworkspace_custom-user-dashboard-backend:latest   apulistech/dlworkspace_custom-user-dashboard-backend:latest

./deploy.py --verbose docker build openresty
docker image  tag  dlworkspace_openresty:latest   apulistech/dlworkspace_openresty:latest

./deploy.py --verbose docker build init-container
docker image  tag  dlworkspace_init-container:latest   apulistech/dlworkspace_init-container:latest


./deploy.py docker build watchdog
docker image  tag  watchdog:1.9   apulistech/watchdog:1.9

./deploy.py docker build gpu-reporter
docker image  tag  dlworkspace_gpu-reporter:latest   apulistech/dlworkspace_gpu-reporter:latest

./deploy.py docker build job-exporter
docker image  tag  job-exporter:1.9   apulistech/job-exporter:1.9

./deploy.py docker build repairmanager2
docker image  tag  dlworkspace_repairmanager2:latest   apulistech/dlworkspace_repairmanager2:latest

# /home/apulis/front-end/DLWorkspace/src/ClusterBootstrap 前端最新分支！
./deploy.py --verbose docker build webui3
docker image  tag  dlworkspace_webui3:latest   apulistech/dlworkspace_webui3:latest

```
* 公司harbor 环境同步镜像

```
```bash
# 后端分支代码路径 
cd /home/apulis//DLWorkspace/src/ClusterBootstrap/
git checkout no_network
git pull
# 重新生成平台配置
./deploy.py --verbose webui

# 更新平台组件
./deploy.py --verbose docker push webui3

./deploy.py --verbose docker push restfulapi2

./deploy.py --nocache docker push custom-user-dashboard-frontend

./deploy.py --nocache docker push custom-user-dashboard-backend

./deploy.py --verbose docker push openresty

./deploy.py --verbose docker push init-container

./deploy.py docker push watchdog

./deploy.py docker push gpu-reporter

./deploy.py docker push job-exporter

./deploy.py docker push repairmanager2

./deploy.py docker push image-label 
./deploy.py docker push aiarts-frontend 
./deploy.py docker push aiarts-backend 
./deploy.py docker push data-platform
```

* 确认 nginx 中AI-Arts配置

```yaml
cat  vim /etc/nginx/conf.other/default.conf
# 核对是否有以下新增的配置
location /AIarts {
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_buffers 16 16k;
    proxy_buffer_size 32k;
    proxy_pass http://localhost:3084/;
}
location / {
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_buffers 16 16k;
    proxy_buffer_size 32k;
    proxy_pass http://localhost:3084/;
}
location /expert {
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_buffers 16 16k;
    proxy_buffer_size 32k;
    proxy_pass http://localhost:3081;
}
```
* 更新平台nginx 配置

```bash
./deploy.py --verbose nginx fqdn
./deploy.py --verbose nginx config
```
* 确认更新后的nginx配置

```bash

root@atlas-gpu01:/home/apulis/DLWorkspace/src/ClusterBootstrap# ll /www/static/dashboard
total 48
drwxr-xr-x 3 root root  4096 Aug  3 09:18 ./
drwxr-xr-x 3 root root  4096 Aug  5 03:24 ../
-rw-r--r-- 1 root root  6273 Aug  3 09:18 asset-manifest.json
-rw-r--r-- 1 root root  3870 Aug  3 09:16 favicon.ico
-rw-r--r-- 1 root root  4423 Aug  3 09:18 index.html
-rw-r--r-- 1 root root 10508 Aug  3 09:18 precache-manifest.b35ce6dc0e55a41796c9764926e0a4d0.js
-rw-r--r-- 1 root root  1203 Aug  3 09:18 service-worker.js
drwxr-xr-x 5 root root  4096 Aug  3 09:18 static/
```
* 重启服务(AMD64)

```bash
./deploy.py --verbose kubernetes stop jobmanager2 restfulapi2 nginx custommetrics repairmanager2 openresty
./deploy.py --verbose kubernetes stop monitor

./deploy.py --verbose kubernetes stop webui3
./deploy.py kubernetes stop custom-user-dashboard
./deploy.py kubernetes stop image-label aiarts-frontend aiarts-backend data-platform
# 需要注意等待相关组件grafana,openstry,jobmanager 的 pod已经terminal后再启用
kubectl wait --for=delete pod/openstry** --timeout=60s

./deploy.py --verbose kubernetes start jobmanager2 restfulapi2 nginx custommetrics repairmanager2 openresty
./deploy.py --verbose kubernetes start monitor

./deploy.py --verbose nginx webui3
./deploy.py --verbose kubernetes start webui3
./deploy.py kubernetes start custom-user-dashboard

./deploy.py kubernetes start image-label aiarts-frontend aiarts-backend data-platform
```

AIArts
-----------------------------------------------------------
*  后端
```
# 如果需要重新拉取代码库
# git clone https://github.com/apulis/AIArtsBackend.git 

cd /home/apulis/AIArtsBackend/deployment
git checkout master
git pull
cat README.md
./build.sh
docker-compose down
docker-compose up -d
```
* 前端

```
# 如果需要重新拉取代码库
# git clone https://github.com/apulis/AIArts.git 

cd /home/apulis/front-end/AIArts
git checkout master
git pull
cat README.md
./build.sh
docker-compose down
docker-compose up -d
```

数据标注平台
-----------------------------------------------------------
* 后台
```bash
cd /home/apulis//DLWorkspace/src/ClusterBootstrap/
git checkout no_network
git pull
./deploy.py --nocache docker push data-platform-backend
./deploy.py kubernetes stop/start data-platform
```
* 前台：
```bash
# 如果需要重新拉取代码库
# git clone https://github.com/apulis/NewObjectLabel.git

cd /home/apulis/front-end/NewObjectLabel/
git checkout master
git pull
cat README.md
./build.sh
docker-compose down
docker-compose up -d
```

FAQ
-------------------------------------------------------------------

1. 在更新前端配置时可能遇到token失效无法拉取代码

    **解决方法：**
    更新代码库中该组件的dockerfile
    ```bash
    cd /home/apulis//DLWorkspace/src/ClusterBootstrap/
    # 以custom-user-dashboard-backend为例
    vim ../docker-images/custom-user-dashboard-backend/Dockerfile
    FROM node:12

    RUN mkdir -p /home/addon_custom_user_dasboard_backend
    WORKDIR /home/addon_custom_user_dasboard_backend
    # 将以下的token '7a3c38292b740a6c6d7db08b759fbbe7f3c1ece3'更新为最新,或者替换为有效的
    RUN git clone --branch dev-with-i18n https://7a3c38292b740a6c6d7db08b759fbbe7f3c1ece3@github.com/apulis/addon_custom_user_dashboard_backend.git /home/addon_custom_user_dasboard_backend
    RUN yarn config set registry 'https://registry.npm.taobao.org'
    RUN yarn
    RUN yarn build

    EXPOSE 5001

    CMD ["yarn", "start:prod"]
    ```

    *数据标注后端data-platform，也是同样处理`../docker-images/data-platform-backend/Dockerfile`*

2. 所有组件已经running，但是WEB打开home也无响应
    **解决方法：**
    检查default域下的nginx服务状态
    ```bash
    kubectl get pods
    kubectl exec -it nginx-cvs26 bash
    ps aux 
    # 检查nginx服务进程是否已启用
    root        26  0.0  0.0  10884  1132 ?        Ss   Aug25   0:00 nginx: master process nginx
    nginx       27  0.1  0.0  41288 34140 ?        S    Aug25   0:44 nginx: worker process
    # 否则启用nginx
    nginx
    # 如果提示配置错误，是因为没有外网域名
    vim /etc/nginx/conf.d/default.conf
    # 删除第5行的servername
    # 再次启用nginx
    nginx
    ```
apulistech/ai-arts-frontend:latest

docker tag apulistech/ai-arts-frontend:latest harbor.sigsus.cn:8443/opensource/apulistech/dlworkspace_aiarts-frontend:1.0.0

docker tag apulistech/ai-arts-frontend:latest harbor.sigsus.cn:8443/sz_gongdianju/apulistech/dlworkspace_aiarts-frontend:1.0.0

harbor.sigsus.cn:8443/opensource/apulistech/dlworkspace_aiarts-backend:1.0

http://10.31.3.220:8001/AIarts/ModelManagement/avisualis?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1aWQiOjMwMDAxLCJ1c2VyTmFtZSI6ImFkbWluIiwiZXhwIjoxNjAyODMxOTQ0LCJpYXQiOjE2MDI2NTkxNDR9.lNsKbUEidOYMqLoGVwynEiWmN_FZXw4rQgtae8_nAz0

* 安装 kfserving

https://github.com/apulis/dev_document/blob/master/backend/kfserving_setup.md

* 同步istio 镜像
docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/istio-proxy:latest
docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/istio-pilot:latest
docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/istio-envoy:latest
docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/istio-envoy-build-env:latest
docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/istio-base:latest

docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/istio-proxy:latest harbor.sigsus.cn:8443/opensource/apulistech/istio-proxy:latest 
docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/istio-pilot:latest harbor.sigsus.cn:8443/opensource/apulistech/istio-pilot:latest 
docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/istio-envoy:latest harbor.sigsus.cn:8443/opensource/apulistech/istio-envoy:latest  
docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/istio-envoy-build-env:latest harbor.sigsus.cn:8443/opensource/apulistech/istio-envoy-build-env:latest 
docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/istio-base:latest harbor.sigsus.cn:8443/opensource/apulistech/istio-base:latest

docker push harbor.sigsus.cn:8443/opensource/apulistech/istio-proxy:latest
docker push harbor.sigsus.cn:8443/opensource/apulistech/istio-pilot:latest
docker push harbor.sigsus.cn:8443/opensource/apulistech/istio-envoy:latest
docker push harbor.sigsus.cn:8443/opensource/apulistech/istio-envoy-build-env:latest
docker push harbor.sigsus.cn:8443/opensource/apulistech/istio-base:latest

* 同步kfserving镜像

docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/kfserving-pytorchserver:1.5.1-gpu
docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/kfserving-storage-initializer
docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/kfserving-kube-rbac-proxy
docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/kfserving-manager

docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/kfserving-pytorchserver:1.5.1-gpu  harbor.sigsus.cn:8443/opensource/apulistech/kfserving-pytorchserver:1.5.1-gpu
docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/kfserving-storage-initializer:latest  harbor.sigsus.cn:8443/opensource/apulistech/kfserving-storage-initializer:latest
docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/kfserving-kube-rbac-proxy:latest  harbor.sigsus.cn:8443/opensource/apulistech/kfserving-kube-rbac-proxy:latest
docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/kfserving-manager:latest  harbor.sigsus.cn:8443/opensource/apulistech/kfserving-manager:latest

docker push harbor.sigsus.cn:8443/opensource/apulistech/kfserving-pytorchserver:1.5.1-gpu
docker push harbor.sigsus.cn:8443/opensource/apulistech/kfserving-storage-initializer:latest
docker push harbor.sigsus.cn:8443/opensource/apulistech/kfserving-kube-rbac-proxy:latest
docker push harbor.sigsus.cn:8443/opensource/apulistech/kfserving-manager:latest

* 同步knative

docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/knative-serving-webhook:latest
docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/knative-serving-queue:latest
docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/knative-serving-controller:latest
docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/knative-serving-autoscaler:latest
docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/knative-serving-activator:latest
docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/knative-net-istio-webhook:latest
docker pull harbor.sigsus.cn:8443/sz_gongdianju/apulistech/knative-net-istio-controller:latest

docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/knative-serving-webhook:latest harbor.sigsus.cn:8443/opensource/apulistech/knative-serving-webhook:latest
docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/knative-serving-queue:latest harbor.sigsus.cn:8443/opensource/apulistech/knative-serving-queue:latest
docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/knative-serving-controller:latest harbor.sigsus.cn:8443/opensource/apulistech/knative-serving-controller:latest
docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/knative-serving-autoscaler:latest harbor.sigsus.cn:8443/opensource/apulistech/knative-serving-autoscaler:latest
docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/knative-serving-activator:latest harbor.sigsus.cn:8443/opensource/apulistech/knative-serving-activator:latest
docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/knative-net-istio-webhook:latest harbor.sigsus.cn:8443/opensource/apulistech/knative-net-istio-webhook:latest
docker tag harbor.sigsus.cn:8443/sz_gongdianju/apulistech/knative-net-istio-controller:latest harbor.sigsus.cn:8443/opensource/apulistech/knative-net-istio-controller:latest

docker push harbor.sigsus.cn:8443/opensource/apulistech/knative-serving-webhook:latest
docker push harbor.sigsus.cn:8443/opensource/apulistech/knative-serving-queue:latest
docker push harbor.sigsus.cn:8443/opensource/apulistech/knative-serving-controller:latest
docker push harbor.sigsus.cn:8443/opensource/apulistech/knative-serving-autoscaler:latest
docker push harbor.sigsus.cn:8443/opensource/apulistech/knative-serving-activator:latest
docker push harbor.sigsus.cn:8443/opensource/apulistech/knative-net-istio-webhook:latest
docker push harbor.sigsus.cn:8443/opensource/apulistech/knative-net-istio-controller:latest

# 同步 kfserving
* istio
docker pull apulistech/istio-pilot:latest-arm64
docker pull apulistech/istio-proxy:latest-arm64
docker pull apulistech/istio-base:latest-arm64
docker pull apulistech/istio-envoy-build-env:latest-arm64
docker pull apulistech/istio-envoy:latest-arm64

docker tag apulistech/istio-pilot:latest-arm64  harbor.sigsus.cn:8443/netherlands/apulistech/istio-pilot:latest-arm64
docker tag apulistech/istio-proxy:latest-arm64  harbor.sigsus.cn:8443/netherlands/apulistech/istio-proxy:latest-arm64
docker tag apulistech/istio-base:latest-arm64   harbor.sigsus.cn:8443/netherlands/apulistech/istio-base:latest-arm64
docker tag apulistech/istio-envoy-build-env:latest-arm64   harbor.sigsus.cn:8443/netherlands/apulistech/istio-envoy-build-env:latest-arm64
docker tag apulistech/istio-envoy:latest-arm64   harbor.sigsus.cn:8443/netherlands/apulistech/istio-envoy:latest-arm64

docker push harbor.sigsus.cn:8443/netherlands/apulistech/istio-pilot:latest-arm64
docker push harbor.sigsus.cn:8443/netherlands/apulistech/istio-proxy:latest-arm64
docker push harbor.sigsus.cn:8443/netherlands/apulistech/istio-base:latest-arm64
docker push harbor.sigsus.cn:8443/netherlands/apulistech/istio-envoy-build-env:latest-arm64
docker push harbor.sigsus.cn:8443/netherlands/apulistech/istio-envoy:latest-arm64   

* kfserving
docker pull apulistech/kfserving-manager:latest-arm64
docker pull apulistech/kfserving-storage-initializer:latest-arm64
docker pull apulistech/kfserving-kube-rbac-proxy:latest-arm64

docker tag apulistech/kfserving-manager:latest-arm64   harbor.sigsus.cn:8443/netherlands/apulistech/kfserving-manager:latest-arm64
docker tag apulistech/kfserving-storage-initializer:latest-arm64   harbor.sigsus.cn:8443/netherlands/apulistech/kfserving-storage-initializer:latest-arm64
docker tag apulistech/kfserving-kube-rbac-proxy:latest-arm64   harbor.sigsus.cn:8443/netherlands/apulistech/kfserving-kube-rbac-proxy:latest-arm64

docker push harbor.sigsus.cn:8443/netherlands/apulistech/kfserving-manager:latest-arm64
docker push harbor.sigsus.cn:8443/netherlands/apulistech/kfserving-storage-initializer:latest-arm64
docker push harbor.sigsus.cn:8443/netherlands/apulistech/kfserving-kube-rbac-proxy:latest-arm64

* knative
docker pull apulistech/knative-serving-queue:latest-arm64
docker pull apulistech/knative-net-istio-controller:latest-arm64
docker pull apulistech/knative-net-istio-webhook:latest-arm64
docker pull apulistech/knative-serving-activator:latest-arm64
docker pull apulistech/knative-serving-controller:latest-arm64
docker pull apulistech/knative-serving-webhook:latest-arm64
docker pull apulistech/knative-serving-autoscaler:latest-arm64


docker tag apulistech/knative-serving-queue:latest-arm64   harbor.sigsus.cn:8443/netherlands/apulistech/knative-serving-queue:latest-arm64
docker tag apulistech/knative-net-istio-controller:latest-arm64   harbor.sigsus.cn:8443/netherlands/apulistech/knative-net-istio-controller:latest-arm64 
docker tag apulistech/knative-net-istio-webhook:latest-arm64    harbor.sigsus.cn:8443/netherlands/apulistech/knative-net-istio-webhook:latest-arm64
docker tag apulistech/knative-serving-activator:latest-arm64    harbor.sigsus.cn:8443/netherlands/apulistech/knative-serving-activator:latest-arm64
docker tag apulistech/knative-serving-controller:latest-arm64   harbor.sigsus.cn:8443/netherlands/apulistech/knative-serving-controller:latest-arm64
docker tag apulistech/knative-serving-webhook:latest-arm64     harbor.sigsus.cn:8443/netherlands/apulistech/knative-serving-webhook:latest-arm64
docker tag apulistech/knative-serving-autoscaler:latest-arm64   harbor.sigsus.cn:8443/netherlands/apulistech/knative-serving-autoscaler:latest-arm64

docker push harbor.sigsus.cn:8443/netherlands/apulistech/knative-serving-queue:latest-arm64
docker push harbor.sigsus.cn:8443/netherlands/apulistech/knative-net-istio-controller:latest-arm64
docker push harbor.sigsus.cn:8443/netherlands/apulistech/knative-net-istio-webhook:latest-arm64
docker push harbor.sigsus.cn:8443/netherlands/apulistech/knative-serving-activator:latest-arm64
docker push harbor.sigsus.cn:8443/netherlands/apulistech/knative-serving-controller:latest-arm64
docker push harbor.sigsus.cn:8443/netherlands/apulistech/knative-serving-webhook:latest-arm64
docker push harbor.sigsus.cn:8443/netherlands/apulistech/knative-serving-autoscaler:latest-arm64


AIArts 有网部署
================================================================================

* Link: https://github.com/apulis/DLWorkspace/blob/no_network/Installation_zh.md

节点组网和基础配置
--------------------------------------------------------------------------------

1. 节点组网

**二层组网配置：**
| 主机名       | 配置    | 计算设备  | 操作系统       | 公网IP        | 子网IP      | 
| ---------- | ------- | -------- | -------------- | ------------ | ----------- |
| master     | 6C64G   | 8 NPU    | ubuntu 18.04.1 | 10.31.3.106:5122 | 172.16.1.100 | 
| worker     | 36C512G | 8 NPU    | ubuntu 18.04.1 | 10.31.3.106:5122 | 172.16.1.100| 

2. 基础配置以 master 节点为例

* 更新系统安装源
    ```bash

    sudo sed -i "s@http://.*archive.ubuntu.com@http://mirrors.huaweicloud.com@g" /etc/apt/sources.list & \
    sudo sed -i "s@http://.*security.ubuntu.com@http://mirrors.huaweicloud.com@g" /etc/apt/sources.list & \
    apt-get update
    ```

* 配置节点Hostname

    * 按照部署规划配置各个节点的主机名
        ```
        vim /etc/hostname
        # 更新内容为master
        # 设置hostname立即生效：
        sudo hostnamectl set-hostname master
        ``` 
* 同步相关代码库(示例)

    ```
      mkdir -p /home/apulis
      cd /home/apulis
      git clone https://gitee.com/apulis/apulis_platform.git
      cd apulis_platform/src/ClusterBootstrap/
    ```   

* 配置公网域名DNS（如不提供公网访问，请跳过此章节）

    ​*需要在DNS提供商如[阿里云](https://dns.console.aliyun.com)控制台进行配置*

    * 主域名：**ascend.cn**
    * 配置示例：

    | 主机记录 | 记录类型 | 记录值 |
    | ----    | ----     | ---- |
    | atlas.ascend.cn | A | xxx.xxx.xxx.xxx |

* 配置集群域名解析

  - 安装resolvconf
    ```
    apt update
    apt install -y resolvconf
    ```
  - 增加短域名   
    ```
    ​mkdir -p /etc/resolvconf/resolv.conf.d/
    ​echo "search apulis.cn" > /etc/resolvconf/resolv.conf.d/base
    sudo resolvconf -u
    ​​# 此处**ascend.cn**即为config.yaml中的domain

  - 为每个节点配置短域名解析：

    ```
    # mkdir -p deploy/etc

    # 配置hosts
    cat << EOF > deploy/etc/hosts
    127.0.0.1       localhost

    172.16.1.100    master
    172.16.1.100    master.ascend.cn
    172.16.1.100    ci.ascend.cn
    172.16.1.101    worker01
    172.16.1.101    worker01.ascend.cn
    10.31.3.222     harbor.sigsus.cn
    EOF

    chmod 666 deploy/etc/hosts
    # 在HOST src/ClusterBootstrap/目录下执行
    cp ./deploy/etc/hosts  /etc/hosts
    # 
    ```

3. 预置部署配置

* 安装部署工具包
```
apt install -y python-pip &\
apt install -y libmysqlclient-dev libcurl4-openssl-dev libssl-dev
pip config set global.index-url https://mirrors.aliyun.com/pypi/simple  # 设置python安装源
pip install -r scripts/requirements.txt
./scripts/prepare_ubuntu_dev.sh
pip install virtualenv
```

* 进入安装目录安装必要依赖
```
cd /home/apulis
virtualenv -p python2.7 pythonenv2.7
. pythonenv2.7/bin/activate              # 退出虚拟环境 deactivate
cd apulis_platform/src/ClusterBootstrap/
pip install -r scripts/requirements.txt  
```

* 创建集群ID

`./deploy.py --verbose -y build`

* 配置节点初始化帐号
```
cd deploy/sshkey
echo "root" > "rootuser"
echo "apulis123" > "rootpasswd"

```

* 安装SSH Key到所有节点

```
# 初始化 sshkey
ssh-keygen -t rsa -b 4096 -C "your_email@example.com"
cp $HOME/.ssh/id* ./deploy/sshkey/
./deploy.py --verbose sshkey install
```
* 同步host配置

```
./deploy.py --verbose copytoall ./deploy/etc/hosts /etc/hosts
```

* 检查网络配置

```
./deploy.py --verbose execonall sudo ls -al
./deploy.py execonall ping master -c 5
```

4. 编译和同步镜像

* 登陆本地hub(示例帐号： haiyuan.bian/Apulis123)
  `scp -r root@10.31.3.222:/etc/docker/certs.d /etc/docker/ & mkdir -p /opt/harbor & ` 
  
   `docker login harbor.sigsus.cn:8443`

1. 编译和同步平台基础组件
    ```
    ./deploy.py --verbose docker push restfulapi2
    ./deploy.py --verbose docker push webui3
    ./deploy.py --nocache docker push custom-user-dashboard-frontend
    ./deploy.py --nocache docker push custom-user-dashboard-backend
    ./deploy.py --verbose docker push openresty
    ./deploy.py --verbose docker push init-container
    ./deploy.py docker push watchdog
    ./deploy.py docker push gpu-reporter
    ./deploy.py docker push job-exporter
    ./deploy.py docker push repairmanager2   
    ```
2. 编译和同步AIArts-Frontend
```
cd /home/apulis/AIArts-Frontend/
docker build -t apulistech/aiarts-frontend:1.0.0 .
docker tag apulistech/aiarts-frontend:1.0.0 harbor.sigsus.cn:8443/testops/apulistech/aiarts-frontend:latest
```
3. 编译和同步AIArts-Backend
    ```
    cd AIArtsBackend/deployment
    bash build.sh
    ```

4. 编译image-label-frontend
docker build -t dlworkspace_image-label:latest . &\
docker tag dlworkspace_image-label:latest harbor.sigsus.cn:8443/testops/apulistech/dlworkspace_image-label:latest  &\
docker push harbor.sigsus.cn:8443/testops/apulistech/dlworkspace_image-label:latest 


5.  编译image-label-backend
    ```
    cd apulis_platform/src/ClusterBootstrap/
    ./deploy.py docker push data-platform-backend
    ```

6. 编译ascend-for-volcano
    * 安装Golang 
    ```
    wget -q https://storage.googleapis.com/golang/getgo/installer_linux
    chmod +x installer_linux 
    ./installer_linux 
    # 更新环境变量
    source ~/.bash_profile
    # 检查版本
    go version
    ```

7. 编译ascend-device-plugin


8. 编译kfserving
IMAGE_PUSH_HUB_URL=harbor.sigsus.cn/testops/apulistech
或者
IMAGE_PUSH_HUB_URL=apulistech
./scripts/kfserving.sh push istio &\
./scripts/kfserving.sh push knative &\
./scripts/kfserving.sh push kfserving


5. 安装和初始化 kubenets

* 安装依赖工具
./deploy.py --verbose sshkey install  &\
./deploy.py --verbose runscriptonall ./scripts/prepare_ubuntu.sh
./deploy.py --verbose runscriptonall ./scripts/prepare_ubuntu.sh continue
./deploy.py --verbose execonall sudo usermod -aG docker dlwsadmin

* 初始化k8s
```
./deploy.py --verbose execonall sudo swapoff -a
./deploy.py runscriptonroles infra worker ./scripts/install_kubeadm.sh

./deploy.py --verbose kubeadm init
./deploy.py --verbose copytoall ./deploy/sshkey/admin.conf /root/.kube/config

./deploy.py --verbose kubeadm join
./deploy.py --verbose -y kubernetes labelservice
./deploy.py --verbose -y labelworker
```

* 渲染集群配置

./deploy.py renderservice
./deploy.py renderimage # 无效
./deploy.py webui
./deploy.py nginx webui3

./deploy.py nginx fqdn
./deploy.py nginx config



* 挂载共享存储

./deploy.py runscriptonroles infra worker ./scripts/install_nfs.sh
./deploy.py --force mount
./deploy.py execonall "df -h"    



* 启动集群服务器

./deploy.py kubernetes start nvidia-device-plugin

./deploy.py kubernetes start mysql
./deploy.py kubernetes start jobmanager2 restfulapi2 nginx custommetrics repairmanager2 openresty
./deploy.py --sudo --background runscriptonall scripts/npu/npu_info_gen.py
./deploy.py kubernetes start monitor

./deploy.py kubernetes start istio
./deploy.py kubernetes start knative kfserving
./deploy.py kubernetes start webui3 custom-user-dashboard image-label aiarts-frontend aiarts-backend data-platform

UPDATE vc SET quota={"nvidia_gpu_amd64": 1} WHERE id=1;